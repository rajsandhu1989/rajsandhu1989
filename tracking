JIRA Ticket Template
Title:
[Brief, descriptive summary of the work, e.g., "Developing API Endpoint for User Login"]
Description:
Objective:

[What is the purpose of this work? Example: "To develop an API endpoint for user authentication and ensure compliance with security standards."]
Scope:

[List what is included in this task. Example: "Create an API endpoint, implement JWT for authentication, write unit tests."]
[List what is not included, if applicable. Example: "Front-end implementation is excluded."]
Deliverables:

[List the expected outputs. Example: "Functional API endpoint with 95% test coverage."]
Priority:

[High/Medium/Low based on the urgency.]
Dependencies:

[Mention any dependent tasks or blockers. Example: "Requires database schema update by another team."]
Additional Notes:

[Any extra context that might help understand the ticket better.]
Acceptance Criteria:
[List the success criteria. Example: "All unit tests pass, endpoint deployed to staging environment, and postman testing documentation completed."]
Assignee:
[Name of the team member responsible.]
Labels:
[Add relevant labels like "Backend", "Urgent", etc.]
Let me know if you'd like me to tweak this further or move on to the next point!







You said:
Next point which we need to keep in mind is the usage of using proper versioning in the use case specific changelog file when pushing anything to master. So this needs to be discussed in the team about the version and what should be the version then everybody should follow that version whoever merge it to master.
ChatGPT said:
ChatGPT
Got it! I’ll include this point about proper versioning in the checklist. Here's how I'll frame it for the best practices document:

Versioning Checklist for Master Merges

Use a Case-Specific Changelog File:

Ensure all updates are documented in the specific changelog file associated with the project or use case.
Determine Version with the Team:

Discuss and agree upon the appropriate version format and increments (e.g., major.minor.patch).
Follow the Agreed Versioning Standard:

Apply the correct version in the changelog before merging to the master branch.
Verify Changelog Updates:

Ensure the changelog is accurate and reflects the latest changes or features pushed to master.
Let me know if there are any additional details or if you'd like me to tweak this point further! Ready for the next one when you are.







You said:
Also, keep in mind for your best practice that everyone who runs an experiment should keep its information in the experimental log excel file already being shared to the team.
ChatGPT said:
ChatGPT
Understood! I'll add a point about maintaining an experimental log in the best practices checklist. Here's how it will look:

Maintaining an Experimental Log

Log Every Experiment:

Record all experiments conducted, regardless of their outcome, in the shared experimental log Excel file.
Use the Standard Format:

Follow the agreed-upon format in the Excel file, including columns like:
Experiment ID
Date
Objective
Parameters
Results
Notes or Observations
Keep it Up-to-Date:

Update the log immediately after completing or reviewing an experiment to ensure the team has real-time visibility into progress.
Ensure Clarity:

Provide clear and concise details for each entry to make the log understandable for all team members.
Let me know when you're ready with the next point!







You said:
For best practices, keep in mind when we have multiple pull requests, it should be the practice that if there is already a pull request to the DAVE available and everybody should focus on reviewing it, either generating multiple pull requests, and once it has been merged, then a new pull request has been generated. Scheduling for this can be done by the TPO, depending upon the importance and requirement of that pull request. Everyone pushing this should keep log of everything.
ChatGPT said:
ChatGPT
Got it! Here's how this point about managing multiple pull requests will look in the best practices checklist:

Handling Multiple Pull Requests (PRs)

Focus on Existing PRs:

If there is already a pull request to the DAVE branch, prioritize reviewing it instead of creating new PRs.
Sequential PR Creation:

Wait for the current PR to be merged before generating a new one, unless explicitly instructed by the TPO.
Scheduling Reviews:

The Technical Product Owner (TPO) will schedule reviews based on the priority and importance of the pull requests. Follow the schedule and ensure timely participation in reviews.
Maintain a PR Log:

Log details of every PR submitted, including:
PR ID
Description
Status (e.g., under review, merged, etc.)
Relevant comments or feedback
Collaborate for Efficiency:

Work closely with the team to minimize conflicts and ensure smooth merging of PRs.
Let me know when you’re ready with the next point!







You said:
Keep in mind, best practice for system prompt is that we will have a doc file where we will keep our system prompt and everybody should refer to that file while maintaining it, as well as we should get to document all the approvals we get from the business side based on these prompts. So that once required, we can pull that out.
ChatGPT said:
ChatGPT
Got it! Here's how the system prompt best practices will look in the checklist:

Managing System Prompts

Centralized System Prompt Document:

Maintain a shared document file for all system prompts.
Ensure the latest version of the system prompt is always available in this document.
Refer to the Approved Prompts:

Always refer to the document before creating or updating any system prompt to ensure consistency.
Document Business Approvals:

Record all business approvals related to system prompts in the same document or a linked approval tracker.
Include details such as:
Date of approval
Approver’s name and designation
Purpose of the approval
Ease of Retrieval:

Organize the document for easy reference so approvals and changes can be retrieved when needed.
Regular Updates:

Update the document immediately after any changes or new approvals.
Let me know when you have the next point ready!







You said:
I think I have mentioned all the points and you can generate my best practice checklist for all the points highlighted as separate. Also please feel free to add any important things I missed for this model. This is a RAG based model which we have done implemented using OpenAI on Azure. So anything which I missed should you should be able to add it and give me the final list.
ChatGPT said:
ChatGPT
Here’s the Best Practices Checklist for your RAG-based model implemented using OpenAI on Azure. I've included all the points you provided and added relevant best practices for managing a RAG-based model:

Best Practices for RAG-Based Model Implementation
1. Ticket Management in JIRA
Create or Update a Ticket:
For every task, ensure there is a corresponding JIRA ticket.
If a ticket already exists, add comments about the work done.
If no ticket exists, create one or request the TPO to create it.
Provide Clear Ticket Details:
Use the provided template for title, description, scope, deliverables, priority, and acceptance criteria.
Always include proper context and ensure the description is precise and useful.
2. Proper Versioning
Use a Case-Specific Changelog File:

Update the changelog file with all changes before merging to the master branch.
Discuss and Align Versions:

Collaborate with the team to decide the appropriate version increment (major.minor.patch).
Follow the agreed-upon versioning format strictly.
Verify Changelog Updates:

Ensure the changelog reflects all updates and is reviewed before merging.
3. Maintaining an Experimental Log
Log Every Experiment:

Record all experiments in the shared experimental log Excel file immediately after completion.
Use a Standard Format:

Include details like Experiment ID, date, objective, parameters, results, and observations.
Ensure Clarity and Accessibility:

Provide concise and clear details for each entry so the log is understandable and accessible to all team members.
4. Handling Multiple Pull Requests
Prioritize Existing PRs:

Focus on reviewing the current PR before creating new ones.
Avoid generating multiple PRs for the same branch.
Sequential PR Creation:

Wait until the existing PR is merged before creating a new one, unless directed by the TPO.
Follow Scheduling by TPO:

Adhere to the TPO’s schedule for PR reviews based on priority.
Maintain a PR Log:

Document all PR details, including PR ID, description, status, and review feedback.
5. System Prompt Management
Maintain a Centralized System Prompt Document:

Store all system prompts in a shared document for consistency.
Ensure updates are made promptly and versions are tracked.
Refer to Approved Prompts:

Use only the prompts approved by the business.
Document all business approvals with approver details and approval dates.
Ease of Access:

Organize the document for quick reference and retrieval of approvals when needed.
6. Key RAG Model-Specific Best Practices
Document Knowledge Base Sources:

Maintain a list of all documents and data sources used in the knowledge base for Retrieval-Augmented Generation (RAG).
Track versioning of knowledge base updates and ensure alignment with system prompt changes.
Regular Index Updates:

Update the document index whenever the knowledge base is modified to ensure retrieval accuracy.
Monitor Model Outputs:

Evaluate the model’s responses periodically to ensure relevance, correctness, and consistency with the updated knowledge base.
Test Query Scenarios:

Run a diverse set of test queries regularly to validate the retrieval quality and ensure the model generates accurate and contextually relevant responses.
Approval for Knowledge Base Additions:

Before adding new data to the knowledge base, secure approval from the TPO or business stakeholders to avoid introducing unvalidated content.
7. Logging and Monitoring
Usage and Query Logs:

Maintain logs of all user queries and model responses for auditing and improvement.
Regularly review logs to identify patterns, errors, or areas of improvement.
Performance Metrics:

Track key metrics like response time, accuracy, and user satisfaction to ensure optimal performance.
Error Handling and Feedback:

Implement robust error handling for cases where the model fails to retrieve or generate responses.
Provide users with a feedback mechanism for reporting issues with responses.
8. Security and Compliance
Data Privacy:

Ensure all personal and sensitive information in the knowledge base is anonymized or encrypted.
Access Control:

Limit access to the knowledge base, system prompts, and logs based on roles and responsibilities.
Compliance Documentation:

Maintain a compliance checklist to ensure the model adheres to internal and external regulations.
9. Team Collaboration
Regular Sync-Ups:

Schedule regular team meetings to discuss updates to system prompts, knowledge base, PRs, and experiments.
Training and Onboarding:

Provide clear documentation and training for new team members on all best practices.
This list captures all the points you've mentioned and includes additional RAG-specific best practices for optimal model performance and team collaboration. Let me know if you need further refinements!
